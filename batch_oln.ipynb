{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsuciu/miniconda3/envs/oln/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/home/vsuciu/miniconda3/envs/oln/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/vsuciu/miniconda3/envs/oln/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.datasets import replace_ImageToTensor\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "from mmcv.parallel import collate, scatter\n",
    "import mmcv\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50, ResNet50_Weights, resnet152, ResNet152_Weights\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n"
     ]
    }
   ],
   "source": [
    "# object detection model\n",
    "config_file = 'configs/oln_box/faster_rcnn_r50_fpn_1x_coco.py'\n",
    "checkpoint_file = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "object_detector = init_detector(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/vsuciu/data/hdvila/videos/'\n",
    "video_dir = os.path.join(root, 'debug')\n",
    "video_fps = [os.path.join(video_dir, d) for d in os.listdir(video_dir) if d[-5:] != '.part']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to extract the pytorch module from object_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mmdet.models.detectors.faster_rcnn.FasterRCNN'>\n"
     ]
    }
   ],
   "source": [
    "print(type(object_detector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "['meta', 'state_dict']\n"
     ]
    }
   ],
   "source": [
    "torch_detector = torch.load('checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth')\n",
    "print(type(torch_detector))\n",
    "print([k for k in torch_detector.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original batch rcnn attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic_light', 'fire_hydrant', 'stop_sign', 'parking_meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports_ball', 'kite', 'baseball_bat', 'baseball_glove', 'skateboard', 'surfboard', 'tennis_racket', 'bottle', 'wine_glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot_dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted_plant', 'bed', 'dining_table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell_phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy_bear', 'hair_drier', 'toothbrush')\n"
     ]
    }
   ],
   "source": [
    "print(object_detector.CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 20, 40, 60, 80]\n"
     ]
    }
   ],
   "source": [
    "vid_reader = mmcv.VideoReader(video_fps[0])\n",
    "frame_idx = [i for i in range(0, 100, 20)]\n",
    "print(frame_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "frames = [vid_reader[i] for i in frame_idx]\n",
    "batch_frames = np.stack(frames, axis=0)\n",
    "print(batch_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bboxes(model, frame, score_thresh):\n",
    "    \"\"\"\n",
    "    model:\n",
    "    frame:\n",
    "    score_thresh:\n",
    "    \"\"\"\n",
    "    result = inference_detector(model, frame)\n",
    "    # print(result)\n",
    "\n",
    "    labels = np.concatenate([\n",
    "        np.full(bbox.shape[0], i, dtype=np.int32)\n",
    "        for i, bbox in enumerate(result)\n",
    "    ])\n",
    "    bboxes = np.vstack(result)\n",
    "    scores = bboxes[:, -1]\n",
    "\n",
    "    if score_thresh > 0:\n",
    "        inds = scores > score_thresh\n",
    "        bboxes = bboxes[inds, :]\n",
    "        labels = labels[inds]\n",
    "        scores = scores[inds]\n",
    "    \n",
    "    bboxes = bboxes.astype(np.int32)\n",
    "\n",
    "    return result, bboxes, labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_data(img_list, model):\n",
    "    reformat_imgs = []\n",
    "    for img in img_list:\n",
    "        cfg = model.cfg\n",
    "        device = next(model.parameters()).device  # model device\n",
    "\n",
    "        # prepare data\n",
    "        if isinstance(img, np.ndarray):\n",
    "            # directly add img\n",
    "            data = dict(img=img)\n",
    "            cfg = cfg.copy()\n",
    "            # set loading pipeline type\n",
    "            cfg.data.test.pipeline[0].type = 'LoadImageFromWebcam'\n",
    "        else:\n",
    "            # add information into dict\n",
    "            data = dict(img_info=dict(filename=img), img_prefix=None)\n",
    "        # build the data pipeline\n",
    "        cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "        test_pipeline = Compose(cfg.data.test.pipeline)\n",
    "        data = test_pipeline(data)\n",
    "        data = collate([data], samples_per_gpu=1)\n",
    "        # just get the actual data from DataContainer\n",
    "        data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]\n",
    "        data['img'] = [img.data[0] for img in data['img']]\n",
    "\n",
    "        # scatter to specified GPU\n",
    "        data = scatter(data, [device])[0]\n",
    "        data['img'][0].to(device)\n",
    "\n",
    "        reformat_imgs.append(data)\n",
    "        \n",
    "\n",
    "    return reformat_imgs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test batch inference method\n",
    "\n",
    "Manually call `object_detector.forward()`\n",
    "\n",
    "When done with a batch of images (`List[np.ndarray()]`), the stack trace is the following:\n",
    "\n",
    "* `BaseDetector.forward` from `mmdetection/mmdet/models/roi_heads/standard_roi_head.py` bound to `TwoStageDetector.aug_test` from `mmdetection/mmdet/models/detectors/two_stage.py`\n",
    "\n",
    "* `self.rpn_head.aug_test_rpn` from `mmdetection/mmdet/models/detectors/two_stage.py` bound to `(TODO, figure out binding)`\n",
    "\n",
    "    * Find out where this leads\n",
    "\n",
    "* `self.roi_head.aud_test` from `mmdetection/mmdet/models/detectors/two_stage.py` bound to `StandardRoIHead.aug_test` from `mmdetection/mmdet/models/roi_heads/standard_roi_head.py`\n",
    "\n",
    "    * `BBoxTestMixin.aug_test_bboxes` from `mmdetection/mmdet/models/roi_heads/test_mixins.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base aug_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsuciu/object_localization_network/mmdet/datasets/utils.py:56: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_stage aug_test - calling self.roi_head.aug_test\n",
      "1\n",
      "80\n",
      "0 [[460.11642     62.754158   991.1607     743.7285       0.99744415]]\n",
      "27 [[5.5363916e+02 3.7316034e+02 7.4738928e+02 7.4429749e+02 1.3386989e-01]\n",
      " [5.1356573e+02 3.2176093e+02 8.9700031e+02 7.4873615e+02 8.1769660e-02]]\n",
      "45 [[1.2465894e+03 1.7366795e+02 1.3327893e+03 2.8916534e+02 8.0856077e-02]]\n",
      "62 [[3.3159723e+02 2.2433337e+02 4.7603149e+02 4.5161020e+02 6.0054678e-02]]\n",
      "67 [[3.3062119e+02 2.3768761e+02 4.7591162e+02 4.6843781e+02 9.6066013e-02]]\n",
      "68 [[1.0962365e+03 1.4370242e+02 1.3020259e+03 2.9505151e+02 7.0088357e-01]\n",
      " [1.0572594e+03 1.1019763e+02 1.3205237e+03 3.5426678e+02 1.2704824e-01]\n",
      " [1.0354945e+03 3.7179543e+01 1.3273271e+03 5.0871283e+02 7.9586133e-02]]\n",
      "69 [[1.0171064e+03 5.3764824e+01 1.3313906e+03 5.9398468e+02 8.7112255e-02]]\n",
      "70 [[1.1080841e+03 1.4529343e+02 1.2940260e+03 2.8342053e+02 9.2800058e-02]]\n",
      "72 [[5.6196468e+01 1.3900958e+01 6.4745679e+02 7.4908209e+02 5.4173738e-01]\n",
      " [2.5777100e+02 7.5362182e+00 8.4151202e+02 7.4421747e+02 2.0073055e-01]\n",
      " [1.0194670e+03 4.0917175e+01 1.3330000e+03 6.0778711e+02 1.6682883e-01]]\n",
      "73 [[1.2476381e+03 1.7036838e+02 1.3329778e+03 2.7629196e+02 1.5314232e-01]]\n"
     ]
    }
   ],
   "source": [
    "reformat_imgs = reformat_data(batch_frames, object_detector)\n",
    "infer = object_detector.forward(\n",
    "    [reformat_imgs[i]['img'][0] for i in range(5)],\n",
    "    [reformat_imgs[0]['img_metas'][0] for i in range(5)],\n",
    "    return_loss=False\n",
    ")\n",
    "print(len(infer))\n",
    "print(len(infer[0]))\n",
    "for class_id, bbox in enumerate(infer[0]):\n",
    "    if len(bbox) > 0:\n",
    "        print(class_id, bbox)\n",
    "# infer_func([batch_frames[0]], [preproc_pipelines[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[ 0 41 45 45 62 68 68 68 70 72 72 72 72 73]\n"
     ]
    }
   ],
   "source": [
    "print(type(batch_frames[0]))\n",
    "result, bboxes, labels, scores = predict_bboxes(\n",
    "    object_detector,\n",
    "    batch_frames[0],\n",
    "    0.1\n",
    ")\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eeb746b603e7fadf611af56fdd0547e9654ee15c307733b03ad5530c6c70b658"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
